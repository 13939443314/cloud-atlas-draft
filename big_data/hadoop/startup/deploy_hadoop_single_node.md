> 本文介绍单节点安装运行Hadoop，以便快速开始使用Hadoop MapReduce和Hadoop Distributed File System(HDFS).

# 环境要求

* 使用Linux作为运行平台，按照官方文档，Hadoop被部署在超过2000个节点上
* 参考 [HadoopJavaVersions](http://wiki.apache.org/hadoop/HadoopJavaVersions)
* 必须安装ssh并且sshd必须备用于Hadoop脚本

# 安装软件

# 参考

* [Hadoop: Setting up a Single Node Cluster](http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/SingleCluster.html)